{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for Image Recognition with MNIST Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sowmya Askani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8kBxCPlA-R3c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "#from keras.datasets import mnist\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwbzL1C_-R3h"
   },
   "source": [
    "### Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wvA_X6qs-R3i",
    "outputId": "16bf31d8-2691-45ea-8935-a86ab20fb478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "40NYz3be-R3m",
    "outputId": "c8abf2e3-e49e-47f8-eb79-a3c17e82f1fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mLeeKDPy-R3r",
    "outputId": "4b726d06-a826-434f-d1c6-38f475b79a3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "j-1NZmua-R3v",
    "outputId": "17b2e07b-070f-482e-e1bc-c330363331ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Xqx0vxJj-R36",
    "outputId": "9780874a-6370-4cc4-84a6-8aa390c1c720"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AMq8mvOE-R39",
    "outputId": "c39ff81f-a4b8-46ba-9be4-ba62e6313666"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5SbIrq9b-R4B",
    "outputId": "85f56395-d6c6-4ddc-b9bf-6e27854c8de8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aCYpjdXF-R4E",
    "outputId": "efb5f10c-751a-46d5-8791-c06300a5f1d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wUc3o_Gf-R4I",
    "outputId": "5b2a4c43-3673-40ec-8ad9-ddff8390171e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxj7PNqM-R4X"
   },
   "source": [
    "### Initialize Weights in Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qI80NClA-R4f"
   },
   "outputs": [],
   "source": [
    "# This function returns a tf.Variable used to store weights in a filter\n",
    "# This variable is initialized with values that can be used to initialize weights \n",
    "# The values are random numbers\n",
    "\n",
    "def initialize_weights(filter_shape):\n",
    "    \n",
    "    init_random_dist = tf.truncated_normal(filter_shape,stddev=0.1)\n",
    "    \n",
    "    return (tf.Variable(init_random_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0krrtDjT-R5E"
   },
   "source": [
    "### Initialize Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_0WdF5eJ-R5J"
   },
   "outputs": [],
   "source": [
    "# This function returns a tf.Variable used to store bias\n",
    "# This variable is initialized with values that can be usedto initialized bias\n",
    "# The value is initialized to 0.1\n",
    "\n",
    "def initialize_bias(bias_shape):\n",
    "    \n",
    "    initial_bias_vals = tf.constant(0.1,shape=bias_shape)\n",
    "    \n",
    "    return (tf.Variable(initial_bias_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAzMnuUn-R5u"
   },
   "source": [
    "### Set Up Convolution Layer and Perform Convolution Computation: Dot Product (x * W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2th0wA_T-R5z"
   },
   "outputs": [],
   "source": [
    "def create_convolution_layer_and_compute_dot_product (inputs, filter_shape):\n",
    "    #Initialize the weights in the filter\n",
    "    filter_initialized_with_weights = initialize_weights(filter_shape)\n",
    "    \n",
    "    #Create a Convolution Layer\n",
    "    conv_layer_outputs = tf.nn.conv2d(inputs,filter_initialized_with_weights, strides=[1,1,1,1],padding ='SAME')\n",
    "    \n",
    "    #Return the convolution layer outputs\n",
    "    return (conv_layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "053ONFw7-R6H"
   },
   "source": [
    "### Set Up Relu Layer and perform Computation: Dot Product + Bias (x.W + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "18Oiyd-J-R6H"
   },
   "outputs": [],
   "source": [
    "def create_relu_layer_and_compute_dotproduct_plus_b(inputs, filter_shape):\n",
    "    \n",
    "    #Initialize bias for each input channel\n",
    "    b = initialize_bias([filter_shape[3]])\n",
    "    \n",
    "    # Perform the computation first by adding: inputs (x * W) + b\n",
    "    # Create a RelU layer associated with the preceding convolution layer\n",
    "    relu_layer_outputs = tf.nn.relu(inputs+b)\n",
    "    \n",
    "    # Return the outputs of the ReLU layer\n",
    "    return (relu_layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6A9K_zz-R6L"
   },
   "source": [
    "### Set Up a Pooling Layer and Reduce Spatial Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LEIdRuiu-R6L"
   },
   "outputs": [],
   "source": [
    "def create_max_pool(inputs):\n",
    "    \n",
    "    #Create a pooling layer\n",
    "    pooling_layer_outputs = tf.nn.max_pool(inputs, ksize=[1,2,2,1],strides = [1,2,2,1],padding='SAME')\n",
    "    \n",
    "    # Return the pooling Layer\n",
    "    return (pooling_layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiRiSHlL-R6O"
   },
   "source": [
    "### Set Up Fully Connected Layer and Perform Computation: (inputs * Weights) + Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lThDJWx6-R6P"
   },
   "outputs": [],
   "source": [
    "def create_fully_connected_layer_and_compute_dotproduct_plus_bias (inputs, output_size):\n",
    "    \n",
    "    #Get the number of input channels from the input\n",
    "    #Inputs: the outputs fro  the preceding Layer or previous operation like reshaping \n",
    "    input_size = int(inputs.get_shape()[1])\n",
    "    \n",
    "    #Initialize the weights of the filter of the FC layet\n",
    "    # Filter shape [in_channels, out_channels]\n",
    "    # Each weight for one filter cell\n",
    "    W = initialize_weights([input_size, output_size])\n",
    "    \n",
    "    #Initialize the bias: each bias one output channel\n",
    "    b = initialize_bias([output_size])\n",
    "    \n",
    "    #Perform the computation for FC layer and then add bias to get the result\n",
    "    fcbias_outputs=tf.matmul(inputs,W)+b\n",
    "    \n",
    "    # Return the results: outputs\n",
    "    return (fcbias_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: Build the convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create placeholders for inputs and labels: x andy_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "J118bDNi-R6T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_29772/627795200.py:3: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Placeholder\n",
    "# Create a placeholder for the inputs data: x\n",
    "x = tf.placeholder(tf.float32,shape=[None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sH_VHNhb-R6a"
   },
   "outputs": [],
   "source": [
    "# Create a placeholder for the labes of the inputs data: y_true\n",
    "y_true = tf.placeholder(tf.float32,shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the input placeholder x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ne2LRIFu-R6d"
   },
   "outputs": [],
   "source": [
    "# Prepare feeding inputs into the 1st conv layer\n",
    "# Reshape the input x: A placeholder\n",
    "# From 1D array (vector) --> original input shape: 4D-input: [batch, H, W, depth channels]\n",
    "# Depth = color channels: gray scale = 1\n",
    "# Reshaped inputs: x_image: [1, 28, 28, 1]\n",
    "\n",
    "x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 1st convolutional layer, ReLU layer, and perform computation: x*W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7kacF38b-R6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_29772/3414433815.py:7: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a first convolution layer\n",
    "conv_layer1=create_convolution_layer_and_compute_dot_product(x_image,filter_shape=[5,5,1,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RBeyA_ag-R6h"
   },
   "outputs": [],
   "source": [
    "#Create the ReLU layer for the 1st convolution layer\n",
    "# Accept the outputs from the 1st conv layer as the inputs\n",
    "# Perform the computation at the layer and rfeturn the output to the layer\n",
    "conv_relu_layer1=create_relu_layer_and_compute_dotproduct_plus_b(conv_layer1,filter_shape=[5,5,1,32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 1st pooling layer and reduce spatial size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "JBr1Vwsp-R6k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_29772/3467863939.py:4: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pooling_layer1 = create_max_pool(conv_relu_layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2nd convolution Layer, RelU Layer and perform computation: x*W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "47y-oa0l-R6p"
   },
   "outputs": [],
   "source": [
    "# Create a 2nd convolutional layer\n",
    "conv_layer2=create_convolution_layer_and_compute_dot_product(pooling_layer1,filter_shape=[5,5,32,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "pUqVytoH-R6s"
   },
   "outputs": [],
   "source": [
    "# Create the ReLU layer for the 2nd convolution layer\n",
    "conv_relu_layer2=create_relu_layer_and_compute_dotproduct_plus_b(conv_layer2,filter_shape=[5,5,32,64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2nd Pooling layer and Reduce Spatial size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "gmk8Glr5-R6v"
   },
   "outputs": [],
   "source": [
    "pooling_layer2 = create_max_pool(conv_relu_layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dljwRD6-R6y"
   },
   "source": [
    "### Reshape/Flatten Data Making It Ready to be Fed into 1st FC layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uOmm-hLr-R6z"
   },
   "outputs": [],
   "source": [
    "# Reshape and flatten the output of the 2nd pooling layer\n",
    "# Prepare to feed the output data into the 1st fully connected layer\n",
    "\n",
    "poolig_layer2_flatten = tf.reshape(pooling_layer2, [-1,7*7*64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create 1st FC Layer, ReLU layer, and Output Data to Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Nkoj0mr--R62"
   },
   "outputs": [],
   "source": [
    "# First, Create the FC (fully connected) layer\n",
    "fc_layer_1_outputs = create_fully_connected_layer_and_compute_dotproduct_plus_bias(poolig_layer2_flatten, output_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "V0b8EvVJ-R69"
   },
   "outputs": [],
   "source": [
    "# Create the ReLU layer of the 1st FC layer\n",
    "fc_relu_layer_1_outputs = tf.nn.relu(fc_layer_1_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dropout Layer and Dropout a Fractiom of Output Randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "aAJHTIQO-R7D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_29772/1686363664.py:2: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "dropout_hold_prob = tf.placeholder(tf.float32)\n",
    "dropout_outputs = tf.nn.dropout(fc_relu_layer_1_outputs, keep_prob=dropout_hold_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create final FC layer, compute (x.W+b), and Produce final outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "INAUNt8T-R7J"
   },
   "outputs": [],
   "source": [
    "y_pred = create_fully_connected_layer_and_compute_dotproduct_plus_bias(dropout_outputs,output_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aohKZlh-R7N"
   },
   "source": [
    "### Define Loss Function and Calculate softmax cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "SzZybHLG-R7N"
   },
   "outputs": [],
   "source": [
    "softmax_cross_entropy_loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred)\n",
    "cross_entropy_mean = tf.reduce_mean(softmax_cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDyBnCeY-R7T"
   },
   "source": [
    "### Create an Optimizer to optimize CNN Model and set learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "EhFcEgfr-R7T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_29772/252171548.py:2: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get an ADAM optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a trainer to traning CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "yUeeAbJy-R7V"
   },
   "outputs": [],
   "source": [
    "#Create a CNN model trainer that can train the model\n",
    "# And optmize the model by minimizing the softmax cross_entropy loss\n",
    "\n",
    "cnn_trainer=optimizer.minimize(cross_entropy_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test CNN Deep learning model on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a variable initializer to Initialize all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "AF26DWPJ-R7Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_29772/2444434795.py:1: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vars_initializer = tf.global_variables_initializer()\n",
    "steps=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run tf.Sessions() to Train and Test Deep Learning CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "VrOYYGs4-R7c",
    "outputId": "66e1dc32-86b4-4817-c5a7-050970eb112d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_29772/613137235.py:1: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_DUPLICATE_LIB_OK=True\n",
      "   KMP_INIT_AT_FORK=FALSE\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=8\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_HAND_THREAD=false\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=true\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_FORKJOIN_FRAMES=true\n",
      "   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_ITT_PREPARE_DELAY=0\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_MWAIT_HINTS=0\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=8M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=8\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USER_LEVEL_MWAIT=false\n",
      "   KMP_USE_YIELD=1\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEBUG=disabled\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED=false\n",
      "   OMP_NUM_THREADS='8'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=8M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_TOOL=enabled\n",
      "   OMP_TOOL_LIBRARIES: value is not defined\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n",
      "2022-04-26 21:15:40.529014: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2022-04-26 21:15:40.530233: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55839fc306b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-04-26 21:15:40.530263: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-04-26 21:15:40.530426: I tensorflow/core/common_runtime/process_util.cc:136] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #156: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31352 thread 0 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31352 thread 1 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31356 thread 3 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31358 thread 5 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31355 thread 2 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31359 thread 6 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31357 thread 4 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31360 thread 7 bound to OS proc set 7\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31361 thread 8 bound to OS proc set 0\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31353 thread 9 bound to OS proc set 1\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31362 thread 10 bound to OS proc set 2\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31364 thread 12 bound to OS proc set 4\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31363 thread 11 bound to OS proc set 3\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31367 thread 15 bound to OS proc set 7\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31365 thread 13 bound to OS proc set 5\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31366 thread 14 bound to OS proc set 6\n",
      "OMP: Info #250: KMP_AFFINITY: pid 29772 tid 31368 thread 16 bound to OS proc set 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON STEP:0 Accuracy:15.64\n",
      "\n",
      "\n",
      "ON STEP:100 Accuracy:95.1\n",
      "\n",
      "\n",
      "ON STEP:200 Accuracy:96.36\n",
      "\n",
      "\n",
      "ON STEP:300 Accuracy:97.32\n",
      "\n",
      "\n",
      "ON STEP:400 Accuracy:97.13\n",
      "\n",
      "\n",
      "ON STEP:500 Accuracy:97.24\n",
      "\n",
      "\n",
      "ON STEP:600 Accuracy:98.0\n",
      "\n",
      "\n",
      "ON STEP:700 Accuracy:97.91\n",
      "\n",
      "\n",
      "ON STEP:800 Accuracy:98.04\n",
      "\n",
      "\n",
      "ON STEP:900 Accuracy:98.03\n",
      "\n",
      "\n",
      "ON STEP:1000 Accuracy:98.34\n",
      "\n",
      "\n",
      "ON STEP:1100 Accuracy:98.53\n",
      "\n",
      "\n",
      "ON STEP:1200 Accuracy:98.56\n",
      "\n",
      "\n",
      "ON STEP:1300 Accuracy:98.52\n",
      "\n",
      "\n",
      "ON STEP:1400 Accuracy:98.72\n",
      "\n",
      "\n",
      "ON STEP:1500 Accuracy:98.37\n",
      "\n",
      "\n",
      "ON STEP:1600 Accuracy:98.74\n",
      "\n",
      "\n",
      "ON STEP:1700 Accuracy:98.63\n",
      "\n",
      "\n",
      "ON STEP:1800 Accuracy:98.61\n",
      "\n",
      "\n",
      "ON STEP:1900 Accuracy:98.65\n",
      "\n",
      "\n",
      "ON STEP:2000 Accuracy:98.91\n",
      "\n",
      "\n",
      "ON STEP:2100 Accuracy:98.61\n",
      "\n",
      "\n",
      "ON STEP:2200 Accuracy:98.9\n",
      "\n",
      "\n",
      "ON STEP:2300 Accuracy:98.72\n",
      "\n",
      "\n",
      "ON STEP:2400 Accuracy:98.73\n",
      "\n",
      "\n",
      "ON STEP:2500 Accuracy:98.78\n",
      "\n",
      "\n",
      "ON STEP:2600 Accuracy:98.83\n",
      "\n",
      "\n",
      "ON STEP:2700 Accuracy:98.69\n",
      "\n",
      "\n",
      "ON STEP:2800 Accuracy:98.65\n",
      "\n",
      "\n",
      "ON STEP:2900 Accuracy:98.83\n",
      "\n",
      "\n",
      "ON STEP:3000 Accuracy:98.97\n",
      "\n",
      "\n",
      "ON STEP:3100 Accuracy:98.74\n",
      "\n",
      "\n",
      "ON STEP:3200 Accuracy:99.05\n",
      "\n",
      "\n",
      "ON STEP:3300 Accuracy:98.75\n",
      "\n",
      "\n",
      "ON STEP:3400 Accuracy:98.82\n",
      "\n",
      "\n",
      "ON STEP:3500 Accuracy:98.98\n",
      "\n",
      "\n",
      "ON STEP:3600 Accuracy:98.95\n",
      "\n",
      "\n",
      "ON STEP:3700 Accuracy:98.78\n",
      "\n",
      "\n",
      "ON STEP:3800 Accuracy:98.99\n",
      "\n",
      "\n",
      "ON STEP:3900 Accuracy:99.0\n",
      "\n",
      "\n",
      "ON STEP:4000 Accuracy:98.92\n",
      "\n",
      "\n",
      "ON STEP:4100 Accuracy:99.05\n",
      "\n",
      "\n",
      "ON STEP:4200 Accuracy:98.64\n",
      "\n",
      "\n",
      "ON STEP:4300 Accuracy:98.88\n",
      "\n",
      "\n",
      "ON STEP:4400 Accuracy:98.81\n",
      "\n",
      "\n",
      "ON STEP:4500 Accuracy:98.96\n",
      "\n",
      "\n",
      "ON STEP:4600 Accuracy:98.87\n",
      "\n",
      "\n",
      "ON STEP:4700 Accuracy:98.99\n",
      "\n",
      "\n",
      "ON STEP:4800 Accuracy:98.86\n",
      "\n",
      "\n",
      "ON STEP:4900 Accuracy:98.99\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(vars_initializer)\n",
    "    results=[]\n",
    "    for i in range(steps):\n",
    "        batch_x,batch_y = mnist.train.next_batch(50)\n",
    "        sess.run(cnn_trainer,feed_dict = {x:batch_x, y_true:batch_y,dropout_hold_prob:0.5})\n",
    "        if i%100==0:\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "            test_accuracy = sess.run(acc, feed_dict = {x:mnist.test.images,y_true:mnist.test.labels,dropout_hold_prob:1.0})\n",
    "            results.append(test_accuracy)\n",
    "            print(f\"ON STEP:{i} Accuracy:{round((test_accuracy*100),2)}\")\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Y1wUp1ut-R7e",
    "outputId": "fc211014-2717-44bd-efd0-9bcfe7e98ee9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.84"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(results)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4HxO57u7-R7g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "phase 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
